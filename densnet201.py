# -*- coding: utf-8 -*-
"""densnet201 dinesh.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7z9AADXdFZA5q1GAkfMbFm5cWgo9NDt
"""

import tensorflow as tf
print(tf.__version__)

import matplotlib.pyplot as plt
import tensorflow as tf
import random
import os
from glob import glob
from matplotlib import pyplot
import cv2
import pandas as pd
import numpy as np
import matplotlib.gridspec as gridspec
import seaborn as sns
import itertools
import sklearn
import scipy
import skimage
from skimage.transform import resize
import csv
from tqdm import tqdm
from sklearn import model_selection
from sklearn.model_selection import train_test_split, learning_curve, KFold, cross_val_score, StratifiedKFold
from sklearn.metrics import confusion_matrix
import keras
from tensorflow.keras.utils import to_categorical  # Correct import for to_categorical
from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator  # Correct import for ImageDataGenerator
from keras import models, layers, optimizers
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from keras.layers import Activation, Dense, Dropout, Flatten
from keras.models import Model

from google.colab import drive
drive.mount('/content/drive')

''' Data Path '''
train_path = '/content/drive/MyDrive/Project2025/oralcancer1'

File=[]
for f in os.listdir(train_path):
    File += [f]

'''  total number of classes '''
print(File)

import tensorflow as tf
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import numpy as np
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# ... (Your data loading and preprocessing code here) ...

# Load DenseNet201
base_model = DenseNet201(input_shape=(128, 128, 3), include_top=False, weights='imagenet', pooling=None)

# Freeze base layers (fine-tuning)
base_model.trainable = False

# Add custom layers
x = base_model.output
x = layers.GlobalMaxPooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
output = layers.Dense(2, activation='softmax')(x)  # Adjust output based on your classes

# Create the model
model = models.Model(inputs=base_model.input, outputs=output)

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Data augmentation
data_aug = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=20, zoom_range=0.2,
                            width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, fill_mode="nearest")

''' reading images '''
train_data = []

''' label encoding '''
mapping={'Non-Cancer':0, 'Cancer':1}
count=0

train_path = '/content/drive/MyDrive/Project2025/oralcancer1' # Assuming train_path is defined

for f in os.listdir(train_path):
    ''' joining path '''
    path = os.path.join(train_path, f)
    for im in os.listdir(path):
        ''' loading an image '''
        img = load_img(os.path.join(path, im), color_mode='rgb', target_size=(128,128))
        ''' converting an image to array '''
        img = img_to_array(img)
        ''' scaling  '''
        img = img / 255.0
        ''' appending image to train_data '''
        train_data.append([img, count])
    count=count+1

train_images, train_labels = zip(*train_data)

''' converting labels into to_categorical '''
train_labels = to_categorical(train_labels)

''' coverting train_images into numpy array '''
train_images = np.array(train_images)

''' converting train_labesl into numpy array '''
train_labels = np.array(train_labels)

''' reshaping images '''
train_images = train_images.reshape(-1,128,128,3)

''' train test split '''
X_train, X_test, y_train, y_test = train_test_split(train_images,train_labels, test_size=0.3,random_state=44)

# Train the model
history = model.fit(data_aug.flow(X_train, y_train, batch_size=8), validation_data=(X_test, y_test), epochs=75)

''' reading images '''

train_data = []

''' label encoding '''
mapping={'Non-Cancer':0, 'Cancer':1}

count=0

for f in os.listdir(train_path):
    ''' joining path '''
    path = os.path.join(train_path, f)
    for im in os.listdir(path):
        ''' loading an image '''
        img = load_img(os.path.join(path, im), color_mode='rgb', target_size=(128,128))
        ''' converting an image to array '''
        img = img_to_array(img)
        ''' scaling  '''
        img = img / 255.0
        ''' appending image to train_data '''
        train_data.append([img, count])
    count=count+1

train_images, train_labels = zip(*train_data)

''' converting labels into to_categorical '''
train_labels = to_categorical(train_labels)

''' coverting train_images into numpy array '''
train_images = np.array(train_images)

''' converting train_labesl into numpy array '''
train_labels = np.array(train_labels)

''' shaep of train_images and train_labels '''
print(train_images.shape)
print(train_labels.shape)

''' reshaping images '''
train_images = train_images.reshape(-1,128,128,3)

''' train test split '''
X_train, X_test, y_train, y_test = train_test_split(train_images,train_labels, test_size=0.3,random_state=44)

''' shape of X_train, X_test, y_train, y_test '''
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

''' data Augmentation '''
data_aug = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=20, zoom_range=0.2,
                    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, fill_mode="nearest")

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import DenseNet201

# Custom layer to wrap tf.reduce_mean and tf.reduce_max
class SpatialAttention(layers.Layer):
    def __init__(self, **kwargs):
        super(SpatialAttention, self).__init__(**kwargs)
        # Initialize Conv2D layer in the __init__ method
        self.conv_layer = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')

    def call(self, inputs):
        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
        # Use the initialized conv_layer here
        spatial_attention = self.conv_layer(tf.concat([avg_pool, max_pool], axis=-1))
        return spatial_attention

# CBAM Attention Block
def cbam_block(feature_map, ratio=8):
    # Channel Attention
    channel_avg = layers.GlobalAveragePooling2D()(feature_map)
    channel_max = layers.GlobalMaxPooling2D()(feature_map)

    # Reshape to match feature_map dimensions
    channel_avg = layers.Reshape((1, 1, channel_avg.shape[-1]))(channel_avg)
    channel_max = layers.Reshape((1, 1, channel_max.shape[-1]))(channel_max)

    shared_dense = layers.Dense(feature_map.shape[-1] // ratio, activation='relu')
    shared_dense_out = layers.Dense(feature_map.shape[-1], activation='sigmoid')

    avg_out = shared_dense_out(shared_dense(channel_avg))
    max_out = shared_dense_out(shared_dense(channel_max))

    channel_attention = layers.Add()([avg_out, max_out])
    channel_attention = layers.Multiply()([feature_map, channel_attention])

    # Spatial Attention (using the custom layer)
    spatial_attention = SpatialAttention()(channel_attention)

    # Apply Spatial Attention
    feature_map = layers.Multiply()([channel_attention, spatial_attention])

    return feature_map

# Base DenseNet201 Model
base_model = DenseNet201(input_shape=(128, 128, 3), include_top=False, weights='imagenet', pooling=None)
base_model.trainable = False  # Freeze base layers

# Add CBAM Attention
x = base_model.output
x = cbam_block(x)

# Global Pooling and Classification
x = layers.GlobalMaxPooling2D()(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.5)(x)
output = layers.Dense(2, activation='softmax')(x) # changed to 2 output nodes

# Final Model
model = models.Model(inputs=base_model.input, outputs=output)

# Compile
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='categorical_crossentropy', # changed to categorical_crossentropy
              metrics=['accuracy'])

# Summary
model.summary()

# Use the previously defined 'model' instead of 'model1'
inp = model.input
''' Hidden Layer '''
x = tf.keras.layers.Dense(128, activation='relu')(model.output) # Changed model1 to model
''' Classification Layer '''
out = tf.keras.layers.Dense(2, activation='softmax')(x)

''' Model '''
model = tf.keras.Model(inputs=inp, outputs=out) # You are overwriting the 'model' variable. Consider renaming this to 'final_model'

''' compile the model '''
model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

''' training '''
history=model.fit(data_aug.flow(X_train, y_train, batch_size=8), validation_data=(X_test, y_test), epochs=75)

################ VISUALIZING IMAGES IN INTERMEDIATE LAYERS  #########################################


################   CODE STARTING ##############################

''' prediction '''
y_pred=model.predict(X_test)

''' retreiving max val from predicted values '''
pred = np.argmax(y_pred,axis=1)

''' retreiving max val from actual values '''
ground = np.argmax(y_test,axis=1)

from sklearn.metrics import classification_report

''' classificaion report '''
print(classification_report(ground,pred))

# Viewing Model Summary
print(model.summary())

##### Checking and extracting the indexes of "Convolutional Layers"
t=list(model.layers)

conv_index=[]
for i in range(len(t)):
  layer=t[i]
  if 'conv' in layer.name:
    conv_index.append(i)

print("Indexes of Convolutional Layers are ",conv_index)

##### Checking layer name and output shapes
for i in conv_index:
  layer=model.layers[i]
  print("layer name is :{}            output Shape is : {}".format(layer.name,layer.output.shape))

###### For Demo Visualizing 1st convolutional layer output
M_conv_1=Model(inputs=model.inputs, outputs=model.layers[1].output)
M_conv_1.summary()

###### Loading Sample Image for the above layer
''' loading an image '''

img = load_img("/content/drive/MyDrive/Project2025/oralcancer1/cancer-dataset/oral_scc_0001.jpg") # Removed the trailing slash from the file path and target_size
''' converting img to array '''
img = img_to_array(img)

''' resizing '''
img = resize(img, (128, 128)) # Resizing the image to 128x128

''' scaling '''
img = img / 255.0

''' expanding dimensions '''
img = np.expand_dims(img, axis=0)

feature_maps=M_conv_1.predict(img)

###### For Demo Visualizing 1st convolutional layer output
M_conv_1=Model(inputs=model.inputs, outputs=model.layers[2].output)
M_conv_1.summary()

from matplotlib import pyplot
square = 4  # Adjust this value to match the number of channels in feature_maps
ix = 1
ax = pyplot.figure(figsize=(5, 5))
for i in range(square):
  for j in range(square):
    # Check if ix is within the bounds of the feature_maps array
    if ix <= feature_maps.shape[3]:
      ax = pyplot.subplot(square, square, ix)
      ax.set_xticks([])
      ax.set_yticks([])
      ax.set_aspect('equal')
      pyplot.imshow(feature_maps[0, :, :, ix - 1], aspect='auto', cmap="hot")
    ix += 1  # Increment ix regardless of whether the image is displayed

pyplot.savefig("CO1.tiff", format="tiff")
pyplot.show()

###### For Demo Visualizing 1st convolutional layer output
M_conv_1=Model(inputs=model.inputs, outputs=model.layers[7].output)
M_conv_1.summary()

feature_maps=M_conv_1.predict(img)

from matplotlib import pyplot
square=4
ix=1
ax=pyplot.figure(figsize=(5,5))
for i in range(square):
  for j in range(square):
    ax=pyplot.subplot(square,square,ix)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_aspect('equal')

    pyplot.imshow(feature_maps[0,:,:,ix-1],aspect='auto',cmap="hot")
    ix+=1


pyplot.savefig("CO1.tiff",format="tiff")
pyplot.show()

###### For Demo Visualizing 1st convolutional layer output
M_conv_1=Model(inputs=model.inputs, outputs=model.layers[9].output)
M_conv_1.summary()

feature_maps=M_conv_1.predict(img)

from matplotlib import pyplot
square=4
ix=1
ax=pyplot.figure(figsize=(5,5))
for i in range(square):
  for j in range(square):
    ax=pyplot.subplot(square,square,ix)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_aspect('equal')

    pyplot.imshow(feature_maps[0,:,:,ix-1],aspect='auto',cmap="hot")
    ix+=1


pyplot.savefig("CO1.tiff",format="tiff")
pyplot.show()

###### For Demo Visualizing 1st convolutional layer output
M_conv_1=Model(inputs=model.inputs, outputs=model.layers[14].output)
M_conv_1.summary()

feature_maps=M_conv_1.predict(img)

from matplotlib import pyplot
square=4
ix=1
ax=pyplot.figure(figsize=(5,5))
for i in range(square):
  for j in range(square):
    ax=pyplot.subplot(square,square,ix)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_aspect('equal')

    pyplot.imshow(feature_maps[0,:,:,ix-1],aspect='auto',cmap="hot")
    ix+=1


pyplot.savefig("CO1.tiff",format="tiff")
pyplot.show()

''' training loss and validation loss graph '''
epochs = range(75)
plt.plot(epochs, history.history['loss'], 'orange', marker=".",  label='Training Loss', linewidth=1)
plt.plot(epochs, history.history['val_loss'], 'g', marker=".", label='Validation Loss', linewidth=1)
#plt.title('Training vs validation loss')
plt.xlabel('Epoch'); plt.ylabel('Loss');
plt.legend(loc=3)
plt.figure()
plt.show()
pyplot.savefig("Loss.tiff",format="tiff")

''' training accuracy and validation accuracy graph '''
epochs = range(75)
plt.plot(epochs, history.history['accuracy'], 'orange', marker=".", label='Training Accuracy', linewidth=1)
plt.plot(epochs, history.history['val_accuracy'], 'g', marker=".", label='Validation Accuracy', linewidth=1)
#plt.title('Training vs validation accuracy')
plt.xlabel('Epoch'); plt.ylabel('Accuracy');
plt.legend(loc=3)
plt.figure()
plt.show()
pyplot.savefig("ACC.tiff",format="tiff")

y_test_arg=np.argmax(y_test,axis=1)
Y_pred = np.argmax(model.predict(X_test),axis=1)

''' checking accuracy score'''
accuracy = accuracy_score(y_test_arg, Y_pred)
print(accuracy)



import seaborn as sns
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test_arg, Y_pred)
f = sns.heatmap(cm, annot=True, fmt='d', cmap="hot")
# labels, title and ticks
f.set_xlabel('Predicted label');f.set_ylabel('True label');
#f.set_title('Confusion Matrix');
f.xaxis.set_ticklabels(['Grade1', 'Grade2']); f.yaxis.set_ticklabels(['cancer','non cancer']);
pyplot.savefig("CM.tiff",format="tiff")

# Evaluating Metrices

TP = cm[1][1]
TN = cm[0][0]
FP = cm[0][1]
FN = cm[1][0]
print('True Positives:', TP)
print('True Negatives:', TN)
print('False Positives:', FP)
print('False Negatives:', FN)

# calculate accuracy
conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))

# calculate mis-classification
conf_misclassification = 1- conf_accuracy

# calculate the sensitivity
conf_sensitivity = (TP / float(TP + FN))
# calculate the specificity
conf_specificity = (TN / float(TN + FP))

# calculate precision
conf_precision = (TN / float(TN + FP))
# calculate NPV
conf_NPV = (TN / float(TN + FN))
# calculate f_1 score
conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))
print('-'*50)
print(f'Accuracy: {round(conf_accuracy,4)}')
print(f'Mis-Classification: {round(conf_misclassification,4)}')
print(f'Sensitivity: {round(conf_sensitivity,4)}')
print(f'Specificity: {round(conf_specificity,4)}')
print(f'Precision: {round(conf_precision,4)}')
print(f'NPV: {round(conf_NPV,4)}')
print(f'f_1 Score: {round(conf_f1,2)}')

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

# Calculate accuracy
conf_accuracy = (float(TP + TN) / float(TP + TN + FP + FN))

# Calculate mis-classification
conf_misclassification = 1 - conf_accuracy

# Calculate sensitivity
conf_sensitivity = (TP / float(TP + FN))

# Calculate specificity
conf_specificity = (TN / float(TN + FP))

# Calculate precision
conf_precision = (TN / float(TN + FP))

# Calculate NPV
conf_NPV = (TN / float(TN + FN))

# Calculate f_1 score
conf_f1 = 4 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))

# Calculate predicted probabilities
y_scores = model.predict_on_batch(X_test)[:, 1]  # Assuming you have a model and input data (X) available

# Calculate false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test_arg, y_scores)  # Replace y_true with your true labels

# Calculate AUC score
auc = roc_auc_score(y_test_arg, y_scores)  # Replace y_true with your true labels

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, 'orange',  label='ROC curve (AUC = %0.4f)' % auc, linewidth=2)
plt.plot([0, 1], [0, 1], 'g', linewidth=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.02])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc="lower right")
plt.show()

print('-' * 50)
print(f'Accuracy: {round(conf_accuracy, 4)}')
print(f'Mis-Classification: {round(conf_misclassification, 4)}')
print(f'Sensitivity: {round(conf_sensitivity, 4)}')
print(f'Specificity: {round(conf_specificity, 4)}')
print(f'Precision: {round(conf_precision, 4)}')
print(f'NPV: {round(conf_NPV, 4)}')
print(f'f_1 Score: {round(conf_f1, 2)}')
